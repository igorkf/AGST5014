---
title: "Homework 4"
author: "Igor Kuivjogi Fernandes"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1 The ANOVA from a randomized complete block experiment output is shown below. In this experiment, 30 experimental units were evaluated.   
```{r, echo=FALSE, results='asis'}
table <- '
|   Source  |    SS   | DF |   MS   |   F   | P |
|:---------:|:-------:|:--:|:------:|:-----:|:-:|
| Treatment | 1010.56 |  4 |    -   | 29.84 | - |
|   Block   |    -    |  - | 64.765 |   -   | - |
|   Error   |  169.33 | 20 |    -   |       |   |
|   Total   | 1503.71 |  - |        |       |   |
'
cat(table)
```

a) Fill in the blanks. 
```{r}
pf(q = 29.84, df1 = 4, df2 = 20, lower.tail = F)  # for treatment
```

```{r}
pf(q = 7.64956, df1 = 5, df2 = 20, lower.tail = F)  # for block
```


```{r, echo=FALSE, results='asis'}
table <- '
|   Source  |    SS   | DF |   MS   |   F   |       P      |
|:---------:|:-------:|:--:|:------:|:-----:|:------------:|
| Treatment | 1010.56 |  4 | 252.64 | 29.84 | 3.544848e-08 |
|   Block   | 323.82  |  5 | 64.765 |7.64956| 0.0003688504 |
|   Error   | 169.33  | 20 | 8.4665 |       |              |
|   Total   | 1503.71 | 29 |        |       |              |
'
cat(table)
```

b) How many blocks were used in this experiment?      
$6$ blocks   

c) What conclusions can you draw?         
The treatment effect is significant when at a significance level of $\alpha = 0.05$.       
The block seems to be useful to reduce the error SS as $\text{MS}_{\text{block}}$ is way bigger than \text{MS}_{\text{error}}.

### 2 An experiment with 12 hybrids of Brachiaria spp was carried out in a randomized block design with three replications. The variable measured was the leaf protein content (P %).   
```{r}
df <- data.frame(
  hybrid = 1:12,
  b1 = c(6.8, 5.8, 6.8, 5.6, 6.9, 3.9, 6, 4.5, 6.1, 5.3, 5.9, 5.2),
  b2 = c(8.9, 6.4, 8.9, 6.2, 6.1, 4.9, 5.5, 5, 5.3, 6.5, 9, 6.4),
  b3 = c(10, 9, 11, 6.9, 7, 5.2, 7.9, 6.1, 8.5, 9.7, 11.2, 7.6)
)
df_long <- reshape(df, direction = 'long', idvar = 'hybrid', varying = c('b1', 'b2', 'b3'), 
                   timevar = 'block', v.names = 'protein')
rownames(df_long) <- 1:nrow(df_long)
df_long$hybrid <- as.factor(df_long$hybrid)
df_long$block <- as.factor(df_long$block)
tibble::glimpse(df_long)
```

a) Formulate the statistical hypotheses H0 and H1 related to the hybrids.   
In this example, the hybrid is a treatment, so we can build a hypothesis on this treatment:   
\begin{align*}
& H_0: \text{the mean leaf protein content is equal across all the hybrids} \\
& H_1: \text{at least one mean differs}
\end{align*}

b) Check the basic assumptions at 5% probability for the purpose of performing the ANAVA (normality of errors: Q-Q Plot; additivity of effects: Tukey test; homoscedasticity: Anscombe and Tukey test (1963)). Interpret the results. Perform the analysis of variance (ANAVA).   

First, let's see whether using a blocking effect reduces error variance:   
```{r}
fit <- aov(protein ~ hybrid, data = df_long)
summary(fit)
```


```{r}
fit_block <- aov(protein ~ hybrid + block, data = df_long)
summary(fit_block)
```

Adding a blocking effect is useful to reduce error variance. In fact, without a blocking effect the treatment effect would not be significant at a significance level of $\alpha = 0.05$ because $\text{p-value} = 0.0642 > \alpha$.

Let's now check the additivity of effects using the Tukey test for additivity effects:
```{r}
daewr::Tukey1df(data.frame(df_long$protein, df_long$hybrid, df_long$block))
```

We reject the null hypothesis that the effects are additive, i.e. we can see that there's interaction between the treatment and the block using a significance level of $\alpha = 0.05$.   
We would want an additive model without interaction between the factor and the block, but let's continue the assumptions for ANOVA now.   

For the Levene's test, the null hypothesis is that the variances are equal across different levels.
```{r}
car::leveneTest(protein ~ hybrid, data = df_long)
```

```{r}
plot(fit_block, which = 5)
```

From the plot, we can see that the variance are homogeneous across the different levels. From the Levene's test, we don't reject the null hypothesis that the variances are equal using a significance level of $\alpha = 0.05$.   

For the Shapiro Wilk test, the null hypothesis in this case is that the residuals come from a normal distribution.    
```{r}
shapiro.test(fit_block$residuals)
```

```{r}
plot(fit_block, which = 2)
```

The Q-Q plot shows that the central points are around the line but there are some points in the tails more far away from the line. From the test, we conclude that the residuals are normally distributed using a significance level of $\alpha = 0.05$, i.e. we don't reject the null hypothesis that the residuals are normally distributed.  

c) Which hybrid performed best?       
```{r}
lsmeans::lsmeans(fit, ~hybrid)
```
The hybrid with the highest protein mean (i.e. performed the best) was the 3rd one.      

d) Create a graph that shows the performance of different hybrids.      
```{r}
boxplot(protein ~ hybrid, data = df_long)
```

### 3 [Use data set: HW4_Q3.csv] The investigators (K. Blenk, M. Chen, G. Evans, J. Chen Ibinson, J. Lamack, and E. Scott, 2000) planned an experiment to investigate how rapid-rise yeast and regular yeast differ in terms of their rate of rising. They were also interested in finding out whether temperature had a significant effect on the rising rate. For each observation, 0.3 gm of yeast and 0.45 gm of sugar were mixed and added to a test tube, together with 6 ml of water. The test tube was placed into a water bath of a specified temperature. The level (height) of the mixture in the test tube was recorded immediately and then again after 15 minutes. Each response is the percentage gain in the height of the mixture in the test tube after 15 minutes. There were three treatment factors:

- Factor C: Initial temperature of water mixed with the yeast and flour (3 levels: 100◦F, 115◦F, 130◦F)     
- Factor D: Type of yeast (2 levels: Rapid rise, Regular)     
- Factor E: Temperature of water bath (2 levels: 70◦F, 85◦F)     

a) Explain in at most two sentences why the treatment combinations should be randomly ordered in each block before measurements.     
The idea of using a block is to control the error. If you know a priori that there's some factor affecting your experiment but this effect is not intended to be analysed you can use it as a block to control the variance. The block controls the variance by grouping more homogeneous experimental units inside the same block, so inside each block you have to randomize the samples to account for independence of experimental units. If you don't randomize the experimental units within each block, you could favor some levels to be in a specific (e.g. spatially) portion of a block.     

b) Obtain the analysis of variance table and explain what conclusions you can draw from it.
```{r}
df <- read.csv('HW4_Q3.csv')
df_long <- reshape(
  df, 
  direction = 'long', 
  idvar = c('water', 'yeast', 'bath'), 
  varying = c('block1', 'block1.1', 'block3'), 
  timevar = 'block', 
  v.names = 'rising'
)
rownames(df_long) <- 1:nrow(df_long)
df_long$water <- as.factor(df_long$water)
df_long$yeast <- as.factor(df_long$yeast)
df_long$bath <- as.factor(df_long$bath)
df_long$block <- as.factor(df_long$block)
tibble::glimpse(df_long)
```

```{r}
fit <- aov(rising ~ water * yeast * bath + block, data = df_long)
summary(fit)
```

The "bath" effect is significant, but all his related interactions "water:bath" and "water:yeast:bath" are not.   
   
The "water" effect is not significant, neither all his related interactions "water:yeast", "water:yeast", "water:bath", and "water:yeast:bath", so the "water" factor is not being significant at all.   

Although the "yeast" effect is not significant, the interaction effect "yeast:bath" is significant so I would keep it in the model.   

c) Create a figure that illustrates the effect of the factor "bath". 
```{r}
boxplot(rising ~ bath, data = df_long)
```

The differences in rate rising means are big. For bath = 1 we have percentages from 0-20% (with an outlier near the 40%), whereas for bath = 2 the percentage is way larger: 20 to almost 100%.   

```{r}
with(df_long, {interaction.plot(bath, yeast, rising, type = 'b',
                           pch = c(1, 2), leg.bty = 'o',
                           main = 'Interaction Plot of Bath and Yeast',
                           xlab = 'Bath', ylab = 'Rate rising (%)',
                           trace.label = 'Yeast')})
```

The interaction plot between "bath" and "yeast" agrees with the ANOVA results: there is an interaction effect between bath and yeast.   

```{r}
with(df_long, {interaction.plot(bath, water, rising, type = 'b',
                           pch = c(1, 2), leg.bty = 'o',
                           main = 'Interaction Plot of Bath and Water',
                           xlab = 'Bath', ylab = 'Rate rising (%)',
                           trace.label = 'Water')})
```

There seems to be no interaction effect, which agrees with the ANOVA output.      

### 4 The data set presented in HW4_Q4.csv comes from an experiment that aimed to evaluate the effect of three doses of herbicide and four different fertilizers on yield. It is a factorial CRD. Run the proper analysis and make interpretations.   
```{r}
df <- read.csv('HW4_Q4.csv')
df$yield <- abs(df$yield)  # fix one negative response point 
df$herbicide_dose <- as.factor(df$herbicide_dose)
df$fertilizer <- as.factor(df$fertilizer)
tibble::glimpse(df)
```

```{r}
with(df, table(herbicide_dose, fertilizer))
```

We have the same number of replications for each combination level.      

Let's see how each factor seems to be affecting the yield:    
```{r}
boxplot(yield ~ herbicide_dose, data = df)
```

Seems that as you increase the herbicide dose, the yield decreases.   

```{r}
boxplot(yield ~ fertilizer, data = df)
```

The type of fertilizer seems to be important to the mean yield as well. 

What about the interactions?      
```{r}
with(df, {interaction.plot(herbicide_dose, fertilizer, yield, type = 'b',
                           pch = c(1, 2, 3, 4), leg.bty = 'o',
                           main = 'Interaction Plot of Herbicide Dose and Fertilizer',
                           xlab = 'Herbicide dose', ylab = 'Yield',
                           trace.label = 'Fertilizer')})
```

There seems to be an interaction effect as well, because as long you increase the herbicide dose the yield decreases in different rates depending on the fertilizer type.   

Let's check the significance of effects with an ANOVA:   
```{r}
fit <- aov(yield ~ herbicide_dose * fertilizer, data = df)
summary(fit)
```

The ANOVA results confirms all the interpretations for the aforementioned plots: both treatments and the interaction are significant using a significance level of $\alpha = 0.05$ because all the $p-values < \alpha$.   

What about the residuals?   
```{r, fig.asp = 1.1, fig.width = 5.3, fig.align = 'center'}
par(mfrow = c(2, 2))
plot(fit, which = 5)
plot(fit, which = 1)
plot(fit, which = 2)
plot(residuals(fit) ~ plot, main = 'Residuals vs Exp. Unit', 
     font.main = 1, data = df, xlab = 'Experimental unit', ylab = 'Residuals')
abline(h = 0, lty = 2)
```

The residuals seems to have homogeneous variance across different herbicide doses.       
The Q-Q plot shows some lines getting away from the Q-Q line.       
The Residuals vs Experiment Unit plot shows a very good horizontal pattern, i.e. which shows an independence of experimental units.    
In general, I would say the model adequacy is good although a slightly deviation in the Q-Q plot.   

### 5 A researcher wants to conduct an experiment to evaluate the effect of irrigation and cover crops on rice yield. Three levels of irrigation were selected (1, 2, and 3 irrigations/per week). Four cover crops were selected (A, B, C, D). They would like to use three replicates. There is a gradient of fertility in the field making it slightly heterogeneous. With the information above, design the proper experiment. Made up some data to analyze this experiment and present the design and the analysis below.   

Let's assume there are 3 subgroups in this population, so we can use 3 blocks.
```{r}
set.seed(2023)
irrigation <- as.factor(c(1, 2, 3))
cover_crops <- as.factor(c('A', 'B', 'C', 'D'))
grid <- expand.grid(irrigation = irrigation, cover_crops = cover_crops)  # all possible combinations
grid <- rbind(grid, grid, grid)  # 3 reps

# first block
b1 <- grid
b1$block <- 1
b1 <- b1[sample(1:nrow(b1)), ]  # randomize within block 1
b1$yield <- rnorm(nrow(b1), mean = 5, sd = 1.9)

# second block
b2 <- grid
b2$block <- 2
b2 <- b2[sample(1:nrow(b2)), ]  # randomize within block 2
b2$yield <- rnorm(nrow(b2), mean = 8, sd = 1.85)

# third block
b3 <- grid
b3$block <- 3
b3 <- b3[sample(1:nrow(b3)), ]  # randomize within block 3
b3$yield <- rnorm(nrow(b3), mean = 12, sd = 1.95)  # the third block favors the yield

# bind blocks
df <- rbind(b1, b2, b3)
rownames(df) <- 1:nrow(df)
df$block <- as.factor(df$block)

# now we can generate specific scenarios for yield across factor combinations
df[(df$irrigation == 1) & (df$cover_crops == 'A'), 'yield'] <- df[
  (df$irrigation == 1) & (df$cover_crops == 'A'), 'yield'
] * 0.8

df[(df$irrigation == 2) & (df$cover_crops == 'C'), 'yield'] <- df[
  (df$irrigation == 2) & (df$cover_crops == 'C'), 'yield'
] * 1.2

df[(df$irrigation == 3) & (df$cover_crops == 'D'), 'yield'] <- df[
  (df$irrigation == 3) & (df$cover_crops == 'D'), 'yield'
] * 1.4

summary(df$yield)  # yield distribution
tibble::glimpse(df)
```

We have 108 rows (36 rows per each block).   

```{r}
boxplot(yield ~ block, data = df)
```
The yield distribution is being affected by the block. 

```{r}
boxplot(yield ~ irrigation, data = df)
```


```{r}
boxplot(yield ~ cover_crops, data = df)
```

Note I favored yield for some factor combinations, e.g. when irrigation = 1 and cover crops = A the yield is lower, whereas for irrigation = 3 and cover crops = D the yield is way bigger. For this reason, we should expect significant
factors.   
As we have a gradient, we could expect that this gradient affects the yield, so we generate fake yield within each block. In this way, we expect that the block helps to account for the error control.
```{r}
with(df, {interaction.plot(irrigation, cover_crops, yield, type = 'b',
                           pch = c(1, 2, 3, 4), leg.bty = 'o',
                           main = 'Interaction Plot of Irrigation and Cover crops',
                           xlab = 'Irrigation (# irrigations/per week)', ylab = 'Yield',
                           trace.label = 'Cover crops')})
```

The interaction seems to be present.    
We know there's a gradient in the field, so we expect the block to be useful for error control.   
ANOVA without block:
```{r}
fit <- aov(yield ~ irrigation * cover_crops, data = df)
summary(fit)
```

ANOVA with block:
```{r}
fit_block <- aov(yield ~ irrigation * cover_crops + block, data = df)
summary(fit_block)
```

We can see that before including the blocks, we would say that all the effects (irrigation, cover_crops, and the interaction) would not be significant. However, when including the block the irrigation and interaction turns to be significant, although cover_crops is not (but the interaction is).      
We can also see that the block reduced the error SS, being useful for controlling the error.   

```{r, fig.asp = 1.1, fig.width = 5.3, fig.align = 'center'}
par(mfrow = c(2, 2))
plot(fit_block, which = 5)
plot(fit_block, which = 1)
plot(fit_block, which = 2)
plot(residuals(fit_block) ~ rownames(df), main = 'Residuals vs Exp. Unit', 
     font.main = 1, data = df, xlab = 'Experimental unit', ylab = 'Residuals')
abline(h = 0, lty = 2)
```
There is homogeneity of variance across treatment levels, the residuals are normal and they show horizontal pattern across the different experimental unit.   

